{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "from polars import selectors as cs\n",
    "from utils import *\n",
    "import os\n",
    "import duckdb\n",
    "\n",
    "\n",
    "\n",
    "import rcs_cataloging as rcc # --> probably need to build first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_data(td_filepath):\n",
    "    with open(td_filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data[0]['TimeDomainData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_postprocessing(df_td):\n",
    "    df_td = df_td.with_columns(\n",
    "    [\n",
    "        pl.col('samplerate').replace({0: 250, 1: 500, 2: 1000}),\n",
    "        pl.col('key0').list.len().alias('packetsizes'),\n",
    "    ]\n",
    ").explode(pl.col('^key.*$')).with_columns(\n",
    "        pl.when( (pl.col('systemTick').shift(-1) - pl.col('systemTick')) == 0).then(pl.lit(None)).otherwise(pl.col('systemTick')).alias('systemTick'),\n",
    "        #pl.when( (pl.col('samplerate').shift(-1) - pl.col('samplerate')) == 0).then(pl.lit(None)).otherwise(pl.col('samplerate')).alias('samplerate'),\n",
    "        pl.when( (pl.col('PacketRxUnixTime').shift(-1) - pl.col('PacketRxUnixTime')) == 0).then(pl.lit(None)).otherwise(pl.col('PacketRxUnixTime')).alias('PacketRxUnixTime'),\n",
    "        pl.when( (pl.col('dataTypeSequence').shift(-1) - pl.col('dataTypeSequence')) == 0).then(pl.lit(None)).otherwise(pl.col('dataTypeSequence')).alias('dataTypeSequence'),\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('PacketGenTime').otherwise(pl.lit(None)).alias('PacketGenTime'),\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('timestamp').otherwise(pl.lit(None)).alias('timestamp'),\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('packetsizes').otherwise(pl.lit(None)).alias('packetsizes'),\n",
    "    )\n",
    "    return assignTime(df_td).rename({'samplerate': 'SampleRateInHz'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accel_data(accel_filepath):\n",
    "    with open(accel_filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data[0]['AccelData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accel_postprocessing(df_accel):\n",
    "    df_accel = df_accel.with_columns(\n",
    "        pl.col('samplerate').replace({0: 65.104}),\n",
    "        pl.col('XSamples').list.len().alias('packetsizes'),\n",
    "    ).explode(pl.col('^*Samples.*$')).with_columns(\n",
    "        pl.when( (pl.col('systemTick').shift(-1) - pl.col('systemTick')) == 0).then(pl.lit(None)).otherwise(pl.col('systemTick')).alias('systemTick'),\n",
    "        #pl.when( (pl.col('samplerate').shift(-1) - pl.col('samplerate')) == 0).then(pl.lit(None)).otherwise(pl.col('samplerate')).alias('samplerate'),\n",
    "        pl.when( (pl.col('PacketRxUnixTime').shift(-1) - pl.col('PacketRxUnixTime')) == 0).then(pl.lit(None)).otherwise(pl.col('PacketRxUnixTime')).alias('PacketRxUnixTime'),\n",
    "        pl.when( (pl.col('dataTypeSequence').shift(-1) - pl.col('dataTypeSequence')) == 0).then(pl.lit(None)).otherwise(pl.col('dataTypeSequence')).alias('dataTypeSequence'),\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('PacketGenTime').otherwise(pl.lit(None)).alias('PacketGenTime'),\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('timestamp').otherwise(pl.lit(None)).alias('timestamp'),\n",
    "        pl.when(pl.col('systemTick').is_not_null()).then('packetsizes').otherwise(pl.lit(None)).alias('packetsizes'),\n",
    "    )\n",
    "    \n",
    "    return assignTime(df_accel).rename({'XSamples': 'accel_XSamples', 'YSamples': 'accel_YSamples', 'ZSamples': 'accel_ZSamples', 'samplerate': 'accel_RateInHz'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time_series(df, epoch_size='1s'):\n",
    "    df = df.group_by_dynamic('localTime', every=epoch_size, period=epoch_size, start_by='datapoint').agg(\n",
    "            [\n",
    "                pl.col('localTime').alias('localTime_vec'),\n",
    "                pl.col('DerivedTime'),\n",
    "                pl.col('channel_0'),\n",
    "                pl.col('channel_1'),\n",
    "                pl.col('channel_2'),\n",
    "                pl.col('channel_3'),\n",
    "                pl.col('localTime_vec').count().alias('epoch_length'),\n",
    "                pl.col('SampleRateInHz'),\n",
    "                pl.col('accel_XSamples'),\n",
    "                pl.col('accel_YSamples'),\n",
    "                pl.col('accel_ZSamples'),\n",
    "                # Include accel sample rate\n",
    "                pl.col('timestamp').mode(),\n",
    "                pl.col('PacketGenTime').mode(),\n",
    "                pl.col('PacketRxUnixTime').mode().alias('HostUnixTime'),\n",
    "            ]\n",
    "        ).filter(\n",
    "            # Remove epochs with more than 1 sample rate\n",
    "            pl.col('SampleRateInHz').list.len() < 2,\n",
    "            # Remove incomplete epochs\n",
    "            pl.col('epoch_length').is_in([125, 250, 500])\n",
    "        ).with_columns(\n",
    "            pl.col('SampleRateInHz').list.first().alias('SampleRateInHz'),\n",
    "        )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check how this looks when in adaptive and when in groups A-C\n",
    "def add_stimulation_parameters(df, settings, adapt):\n",
    "    if adapt is not None:\n",
    "        df = df.join_asof(adapt.select(\n",
    "                'StimRateInHz', 'AmplitudeInMilliamps'\n",
    "            ), \n",
    "            on='HostUnixTime', how='left').join_asof(settings.select(\n",
    "                'PulseWidthInMicroseconds'\n",
    "            ),\n",
    "            on='HostUnixTime', how='left')\n",
    "    else:\n",
    "        df = df.join_asof(settings.select(\n",
    "                'StimRateInHz', 'AmplitudeInMilliamps', 'PulseWidthInMicroseconds'\n",
    "            ), \n",
    "            on='HostUnixTime', how='left')\n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col('StimRateInHz').backward_fill(),\n",
    "        pl.col('AmplitudeInMilliamps').backward_fill(),\n",
    "        pl.col('PulseWidthInMicroseconds').backward_fill(),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_session_tables(directory, epoch_size='500ms'):\n",
    "    assert epoch_size == '500ms', 'Only 500ms epoch size is supported at the moment, because of filtering on epoch size.'\n",
    "    \n",
    "    # Cycle sessions\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for subdir in dirs:\n",
    "            subdirectory_path = os.path.join(root, subdir)\n",
    "            # Get Device directory\n",
    "            for subroot, subdirs, subfiles in os.walk(subdirectory_path):\n",
    "                for subsubdir in subdirs:\n",
    "                    if 'Device' in subsubdir:\n",
    "                        device_subdirectory_path = os.path.join(subroot, subsubdir)\n",
    "                        # Cycle through the files in the device subdirectory, get corresponding tables\n",
    "                        \n",
    "                        # Time Domain Data\n",
    "                        td_data = get_td_data(os.path.join(device_subdirectory_path, 'RawDataTD.json'))\n",
    "                        df_td = rcc.loop_and_table_td_data(td_data)\n",
    "                        df_td = td_postprocessing(df_td)\n",
    "                        \n",
    "                        # Accelerometery Data\n",
    "                        accel_data = get_accel_data(os.path.join(device_subdirectory_path, 'RawDataAccel.json'))\n",
    "                        df_accel = rcc.loop_and_table_accel_data(accel_data)\n",
    "                        df_accel = accel_postprocessing(df_accel)\n",
    "                        \n",
    "                        # Aggregate TD and Accel data\n",
    "                        accel_samplerate = df_accel.select(pl.col('accel_RateInHz').unique()).item()\n",
    "                        df = df_td.sort('DerivedTime').join_asof(\n",
    "                            df_accel.sort('DerivedTime').select([\n",
    "                                pl.col('DerivedTime'),\n",
    "                                pl.col('accel_RateInHz'),\n",
    "                                pl.col('^.*Samples.*$')\n",
    "                            ]),\n",
    "                            on='DerivedTime',\n",
    "                            strategy='nearest',\n",
    "                            tolerance=1000/accel_samplerate,\n",
    "                        ).with_columns(\n",
    "                            pl.from_epoch(pl.col('DerivedTime'), time_unit='ms').dt.convert_time_zone('America/Los_Angeles').alias('localTime'),\n",
    "                        )\n",
    "                        \n",
    "                        # Epoch Time Series data\n",
    "                        df = epoch_time_series(df, epoch_size=epoch_size)\n",
    "                        \n",
    "                        # Stim Settings\n",
    "                        settings = process_device_settings(json.load(open(os.path.join(device_subdirectory_path, 'Settings.json'))))\n",
    "                        # Clean up settings table\n",
    "                        cols = settings.columns[2:]\n",
    "                        settings_col = cs.by_name(*cols)\n",
    "                        settings.filter(~pl.all_horizontal(settings_col.is_null())).rename({'RateInHz': 'StimRateInHz'})\n",
    "                        \n",
    "                        # Event log\n",
    "                        event_log = parse_event_log(json.load(open(os.path.join(device_subdirectory_path, 'EventLog.json'))))\n",
    "                        \n",
    "                        # Adaptive Table\n",
    "                        df_adaptive = parse_adaptive_log(json.load(open(os.path.join(device_subdirectory_path, 'AdaptiveLog.json'))))\n",
    "                        \n",
    "                        # Add stimulation parameters (Hz, Amp, pulse width) to the epoch table\n",
    "                        df = add_stimulation_parameters(df, settings, df_adaptive)\n",
    "                        \n",
    "                        return df, settings, event_log, df_adaptive\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/media/dropbox_hdd/Starr Lab Dropbox/RC+S Patient Un-Synced Data/RCS02 Un-Synced Data/SummitData/SummitContinuousBilateralStreaming/RCS02L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "channel_0\n\nError originated just after this operation:\nDF [\"index\", \"timestamp\", \"PacketGenTime\", \"PacketRxUnixTime\"]; PROJECT */20 COLUMNS; SELECTION: \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1427441/1434395177.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_adaptive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_session_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1427441/2991197491.py\u001b[0m in \u001b[0;36madd_session_tables\u001b[0;34m(directory, epoch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                         \u001b[0;31m# Epoch Time Series data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0;31m# Stim Settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1427441/440332067.py\u001b[0m in \u001b[0;36mepoch_time_series\u001b[0;34m(df, epoch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mepoch_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     df = df.group_by_dynamic('localTime', every=epoch_size, period=epoch_size, start_by='datapoint').agg(\n\u001b[0m\u001b[1;32m      3\u001b[0m             [\n\u001b[1;32m      4\u001b[0m                 \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localTime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localTime_vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DerivedTime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sleepclass/lib/python3.10/site-packages/polars/dataframe/group_by.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *aggs, **named_aggs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \"\"\"\n\u001b[1;32m   1055\u001b[0m         return (\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             .group_by_dynamic(\n\u001b[1;32m   1058\u001b[0m                 \u001b[0mindex_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sleepclass/lib/python3.10/site-packages/polars/lazyframe/frame.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001b[0m\n\u001b[1;32m   1938\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mInProcessQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_concurrently\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrap_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: channel_0\n\nError originated just after this operation:\nDF [\"index\", \"timestamp\", \"PacketGenTime\", \"PacketRxUnixTime\"]; PROJECT */20 COLUMNS; SELECTION: \"None\""
     ]
    }
   ],
   "source": [
    "df, settings, event_log, df_adaptive = add_session_tables(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcs_nums = ['0' + str(i) for i in range(1, 10)] + [str(i) for i in range(10, 21)]\n",
    "side = ['L', 'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
